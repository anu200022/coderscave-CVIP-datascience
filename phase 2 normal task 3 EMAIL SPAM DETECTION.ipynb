{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a5ffc5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "486fe14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\nth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\n( see a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\nho ho ho , we ' re arou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\nthis deal is to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\nth...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\n( see a...   \n",
       "2        3624   ham  Subject: neon retreat\\nho ho ho , we ' re arou...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\nthis deal is to ...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 1: Collect the dataset\n",
    "data = pd.read_csv(r'C:\\Users\\Anubha\\Downloads\\archive\\spam_ham_dataset.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3baf5059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Clean and preprocess the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "62b8037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['text'])  # Assuming the email text is stored in a column named 'text'\n",
    "y = data['label']  # Assuming the labels (spam or non-spam) are stored in a column named 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e27404a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Split the data into training and testing sets\n",
    "model = MultinomialNB()  # You can use other models such as SVM or RandomForest\n",
    "model.fit(X_train, y_train)  # Train the model on the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9bd9aac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.978743961352657\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = model.predict(X_test)  # Predict on the testing data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3ab21a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\nth...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\n( see a...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: neon retreat\\nho ho ho , we ' re arou...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : indian springs\\nthis deal is to ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages label\n",
       "0  Subject: enron methanol ; meter # : 988291\\nth...   ham\n",
       "1  Subject: hpl nom for january 9 , 2001\\n( see a...   ham\n",
       "2  Subject: neon retreat\\nho ho ho , we ' re arou...   ham\n",
       "3  Subject: photoshop , windows , office . cheap ...  spam\n",
       "4  Subject: re : indian springs\\nthis deal is to ...   ham"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.rename(columns={'text': 'messages', 'label': 'label'})\n",
    "\n",
    "# Step 3: Extract relevant columns\n",
    "data = data[['messages', 'label']]\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4ffbd169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c704bc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame._add_numeric_operations.<locals>.sum of       messages  label\n",
       "0        False  False\n",
       "1        False  False\n",
       "2        False  False\n",
       "3        False  False\n",
       "4        False  False\n",
       "...        ...    ...\n",
       "5166     False  False\n",
       "5167     False  False\n",
       "5168     False  False\n",
       "5169     False  False\n",
       "5170     False  False\n",
       "\n",
       "[5171 rows x 2 columns]>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b0067117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Anubha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1e553949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    # remove special characters\n",
    "    text = re.sub(r'[^0-9a-zA-Z]', ' ', text)\n",
    "    # remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # remove stopwords\n",
    "    text = \" \".join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9d2c9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['clean_text'] = data['messages'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1262aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['clean_text']\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d8ff011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c4995c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5171,)\n",
      "(4136,)\n",
      "(1035,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "255bbfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction = TfidfVectorizer(min_df = 1, stop_words='english')\n",
    "\n",
    "X_train_features = feature_extraction.fit_transform(X_train)\n",
    "X_test_features = feature_extraction.transform(X_test)\n",
    "\n",
    "# convert Y_train and Y_test values as integers\n",
    "\n",
    "#Y_train = Y_train.astype('int')\n",
    "#Y_test = Y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "686d40a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2209    subject hplc wellhead daren list deals need mo...\n",
      "2000    subject mobil chemical hpl meter 1256 expense ...\n",
      "5030    subject revised nom 5 5 eastrans revised nom 5...\n",
      "1376    subject exxon company usa global 96035668 sita...\n",
      "1564    subject pharmacy nx want cheap pain killers ht...\n",
      "                              ...                        \n",
      "789     subject incr ease yo ur man hood 4 5 inch es g...\n",
      "968     subject subscribers receive first notice run a...\n",
      "1667    subject neon march 28 neon lesson march 28 th ...\n",
      "3321    subject first delivery pure resources l p vanc...\n",
      "1688    subject enhance chest size email loading image...\n",
      "Name: clean_text, Length: 4136, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9bcfc68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3871)\t0.13387711316973605\n",
      "  (0, 531)\t0.14556222812251965\n",
      "  (0, 30432)\t0.08468916670398006\n",
      "  (0, 43249)\t0.14556222812251965\n",
      "  (0, 3890)\t0.14556222812251965\n",
      "  (0, 548)\t0.14556222812251965\n",
      "  (0, 37242)\t0.11275796314501375\n",
      "  (0, 2908)\t0.11535664415295803\n",
      "  (0, 456)\t0.14556222812251965\n",
      "  (0, 26281)\t0.09506000151609588\n",
      "  (0, 36171)\t0.11400727959297849\n",
      "  (0, 2478)\t0.13872687405852518\n",
      "  (0, 521)\t0.14556222812251965\n",
      "  (0, 16799)\t0.11843023142166303\n",
      "  (0, 22028)\t0.13387711316973605\n",
      "  (0, 2706)\t0.14556222812251965\n",
      "  (0, 522)\t0.14556222812251965\n",
      "  (0, 32041)\t0.07311834410351342\n",
      "  (0, 19402)\t0.04211028825505044\n",
      "  (0, 2537)\t0.13872687405852518\n",
      "  (0, 517)\t0.14556222812251965\n",
      "  (0, 19420)\t0.14556222812251965\n",
      "  (0, 16628)\t0.24438399643390496\n",
      "  (0, 3875)\t0.14556222812251965\n",
      "  (0, 836)\t0.14556222812251965\n",
      "  :\t:\n",
      "  (4135, 8871)\t0.07154271542163933\n",
      "  (4135, 16152)\t0.07327358549803296\n",
      "  (4135, 26919)\t0.07154271542163933\n",
      "  (4135, 15682)\t0.07812310961344454\n",
      "  (4135, 14164)\t0.07812310961344454\n",
      "  (4135, 11830)\t0.07539199926380867\n",
      "  (4135, 4961)\t0.07539199926380867\n",
      "  (4135, 7393)\t0.07154271542163933\n",
      "  (4135, 10236)\t0.06669319130622776\n",
      "  (4135, 29015)\t0.057994383348646844\n",
      "  (4135, 22445)\t0.05353240292261735\n",
      "  (4135, 14387)\t0.05726375354549545\n",
      "  (4135, 16528)\t0.07154271542163933\n",
      "  (4135, 42937)\t0.06496232122983413\n",
      "  (4135, 16208)\t0.06769343157946998\n",
      "  (4135, 26392)\t0.046488819206390516\n",
      "  (4135, 14279)\t0.06669319130622776\n",
      "  (4135, 27697)\t0.031300464660012135\n",
      "  (4135, 16466)\t0.03146157037949769\n",
      "  (4135, 38704)\t0.04124090788006661\n",
      "  (4135, 43401)\t0.05920796972538574\n",
      "  (4135, 20738)\t0.05068335935369024\n",
      "  (4135, 14510)\t0.056585357723181545\n",
      "  (4135, 36171)\t0.06420243561903816\n",
      "  (4135, 38925)\t0.009493502067611905\n"
     ]
    }
   ],
   "source": [
    "print(X_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "31252221",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "00a1d557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_features, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dfc262ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_on_training_data = model.predict(X_train_features)\n",
    "accuracy_on_training_data = accuracy_score(Y_train, prediction_on_training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1261ebdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data :  0.9970986460348162\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training data : ', accuracy_on_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "916e0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a9a0aa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spam']\n",
      "Spam mail\n"
     ]
    }
   ],
   "source": [
    "input_mail = [\"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times\"]\n",
    "\n",
    "# convert text to feature vectors\n",
    "input_data_features = feature_extraction.transform(input_mail)\n",
    "\n",
    "# making prediction\n",
    "\n",
    "prediction = model.predict(input_data_features)\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "if (prediction[0]==1):\n",
    "  print('Ham mail')\n",
    "\n",
    "else:\n",
    "  print('Spam mail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5cf787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
